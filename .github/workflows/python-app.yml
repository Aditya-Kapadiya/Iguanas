# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: Python application

on:
  push:
    branches: [ pylint_workflow ]
  pull_request:
    branches: [ pylint_workflow ]

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8]
    env:
      PYTHON_VERSION: ${{ matrix.python-version }}
      SPARK_LOCAL_IP: 127.0.0.1
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |        
        python -m pip install --upgrade pip
        pip install flake8 pytest
        # if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        pip install .        
        pip install .[dev]
        python -m ipykernel install --user --name iguanas
    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    - name: Test non-Spark modules with pytest
      run: |        
        shopt -s extglob
        pytest iguanas/*/tests/!(*spark*) -vv        
        pytest examples/!(*spark*) --nbmake --nbmake-kernel=iguanas
        pytest iguanas/*/examples/!(*spark*) --nbmake --nbmake-kernel=iguanas
        shopt -u extglob  
    - name: Install Spark dependencies
      run: |        
        pip install .[spark]        
    - name: Test Spark modules with pytest
      run: |                
        pytest iguanas/*/tests/*spark*
        pytest iguanas/*/examples/*spark* --nbmake --nbmake-kernel=iguanas
      